{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c247d9-00cf-43f1-a393-179aa02a7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c18224-2a82-4238-937d-d8f93e3af32a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..Resources/jobs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read the data into a Pandas DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m jobs_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m..Resources/jobs.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m jobs_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..Resources/jobs.csv'"
     ]
    }
   ],
   "source": [
    "# Read the data into a Pandas DataFrame\n",
    "jobs_df = pd.read_csv('..Resources/jobs.csv')\n",
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133be9ad-ec88-48f7-b940-008477806762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a Pandas DataFrame\n",
    "income_df = pd.read_csv('Resources/income.csv')\n",
    "income_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43850744-4e8e-49ea-a0d2-7dd6179002dc",
   "metadata": {},
   "source": [
    "# JOBS AND INCOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed506b-0375-4e38-9725-fe495f0909e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a brief summary of the crowdfunding_info DataFrame.\n",
    "jobs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b1ccf7-c8dd-49c7-9a03-6dab4d5570fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS                     0\n",
       "State                    0\n",
       "County                   0\n",
       "UnempRate2020           85\n",
       "PctEmpChange1920        85\n",
       "                        ..\n",
       "NumCivLaborforce2013     6\n",
       "NumUnemployed2007        8\n",
       "NumEmployed2007          8\n",
       "NumCivLaborforce2007     8\n",
       "NumCivLaborforce2017     6\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values:\n",
    "jobs_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac93dec6-9b8c-4b12-8aa6-badaa84aa916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS                    0\n",
       "State                   0\n",
       "County                  0\n",
       "UnempRate2020           0\n",
       "PctEmpChange1920        0\n",
       "                       ..\n",
       "NumCivLaborforce2013    0\n",
       "NumUnemployed2007       0\n",
       "NumEmployed2007         0\n",
       "NumCivLaborforce2007    0\n",
       "NumCivLaborforce2017    0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing null values with zeros\n",
    "jobs_df = jobs_df.fillna(0)\n",
    "jobs_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d04b1f1e-2fbf-434e-bbf6-cb73eb710f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS                      0\n",
       "State                     0\n",
       "County                    0\n",
       "Median_HH_Inc_ACS         5\n",
       "PerCapitaInc              5\n",
       "Poverty_Rate_0_17_ACS     6\n",
       "Poverty_Rate_ACS          5\n",
       "Deep_Pov_All              5\n",
       "Deep_Pov_Children         5\n",
       "NumAll_inPOV_ACS          5\n",
       "PCTPOV017                85\n",
       "POV017                   85\n",
       "MedHHInc                 85\n",
       "POVALL                   85\n",
       "PCTPOVALL                85\n",
       "Num_inPOV_0_17_ACS        5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nulls in 'income.csv'?\n",
    "income_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16020fc7-0c39-4e95-9667-dd4b5673e38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS                     0\n",
       "State                    0\n",
       "County                   0\n",
       "Median_HH_Inc_ACS        0\n",
       "PerCapitaInc             0\n",
       "Poverty_Rate_0_17_ACS    0\n",
       "Poverty_Rate_ACS         0\n",
       "Deep_Pov_All             0\n",
       "Deep_Pov_Children        0\n",
       "NumAll_inPOV_ACS         0\n",
       "PCTPOV017                0\n",
       "POV017                   0\n",
       "MedHHInc                 0\n",
       "POVALL                   0\n",
       "PCTPOVALL                0\n",
       "Num_inPOV_0_17_ACS       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing null values with zeros\n",
    "income_cleaned_df = income_df.fillna(0)\n",
    "income_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd84f0b2-0dc7-4366-acc6-d0c12cd121dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs_cleaned_df = economic_atlas_rural_america_df.drop(columns=['PctEmpChange1920', 'PctEmpChange1819', 'PctEmpChange1020', 'PctEmpChange0720', 'PctEmpChange0710'])\n",
    "# jobs_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0718703d-4432-4e55-8c6e-d369c06c5e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was saved to 'Resources/income_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file and Export\n",
    "income_cleaned = 'Resources/income_cleaned.csv'\n",
    "income_cleaned_df.to_csv(income_cleaned, index=False)\n",
    "print(f\"Data was saved to '{income_cleaned}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6e0584-a68e-4cf4-bb44-41a3b82ef2a4",
   "metadata": {},
   "source": [
    "# JOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ffc5ee9-c73b-4646-9336-9d462a86cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>PctEmpAgriculture</th>\n",
       "      <th>PctEmpMining</th>\n",
       "      <th>PctEmpConstruction</th>\n",
       "      <th>PctEmpManufacturing</th>\n",
       "      <th>PctEmpTrade</th>\n",
       "      <th>PctEmpTrans</th>\n",
       "      <th>PctEmpInformation</th>\n",
       "      <th>PctEmpFIRE</th>\n",
       "      <th>PctEmpServices</th>\n",
       "      <th>PctEmpGovt</th>\n",
       "      <th>NumCivEmployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.259202</td>\n",
       "      <td>0.512723</td>\n",
       "      <td>6.592262</td>\n",
       "      <td>10.108008</td>\n",
       "      <td>13.745334</td>\n",
       "      <td>5.363914</td>\n",
       "      <td>2.011223</td>\n",
       "      <td>6.555840</td>\n",
       "      <td>49.244129</td>\n",
       "      <td>4.607366</td>\n",
       "      <td>154842185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.993190</td>\n",
       "      <td>0.398210</td>\n",
       "      <td>6.604990</td>\n",
       "      <td>14.332569</td>\n",
       "      <td>14.083735</td>\n",
       "      <td>5.454652</td>\n",
       "      <td>1.519607</td>\n",
       "      <td>5.523166</td>\n",
       "      <td>45.678045</td>\n",
       "      <td>5.411837</td>\n",
       "      <td>2097384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>0.517902</td>\n",
       "      <td>0.354783</td>\n",
       "      <td>6.072099</td>\n",
       "      <td>12.951635</td>\n",
       "      <td>12.445967</td>\n",
       "      <td>6.797977</td>\n",
       "      <td>1.362042</td>\n",
       "      <td>5.978305</td>\n",
       "      <td>44.082864</td>\n",
       "      <td>9.436424</td>\n",
       "      <td>24522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>0.952772</td>\n",
       "      <td>0.257648</td>\n",
       "      <td>8.585460</td>\n",
       "      <td>9.249035</td>\n",
       "      <td>16.477900</td>\n",
       "      <td>5.003628</td>\n",
       "      <td>1.525907</td>\n",
       "      <td>7.520165</td>\n",
       "      <td>45.203016</td>\n",
       "      <td>5.224469</td>\n",
       "      <td>95091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>5.717342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.810888</td>\n",
       "      <td>23.047664</td>\n",
       "      <td>12.813503</td>\n",
       "      <td>6.632592</td>\n",
       "      <td>0.606205</td>\n",
       "      <td>3.720433</td>\n",
       "      <td>33.638417</td>\n",
       "      <td>7.012956</td>\n",
       "      <td>8413.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS State         County  PctEmpAgriculture  PctEmpMining  \\\n",
       "0     0    US  United States           1.259202      0.512723   \n",
       "1  1000    AL        Alabama           0.993190      0.398210   \n",
       "2  1001    AL        Autauga           0.517902      0.354783   \n",
       "3  1003    AL        Baldwin           0.952772      0.257648   \n",
       "4  1005    AL        Barbour           5.717342      0.000000   \n",
       "\n",
       "   PctEmpConstruction  PctEmpManufacturing  PctEmpTrade  PctEmpTrans  \\\n",
       "0            6.592262            10.108008    13.745334     5.363914   \n",
       "1            6.604990            14.332569    14.083735     5.454652   \n",
       "2            6.072099            12.951635    12.445967     6.797977   \n",
       "3            8.585460             9.249035    16.477900     5.003628   \n",
       "4            6.810888            23.047664    12.813503     6.632592   \n",
       "\n",
       "   PctEmpInformation  PctEmpFIRE  PctEmpServices  PctEmpGovt  NumCivEmployed  \n",
       "0           2.011223    6.555840       49.244129    4.607366     154842185.0  \n",
       "1           1.519607    5.523166       45.678045    5.411837       2097384.0  \n",
       "2           1.362042    5.978305       44.082864    9.436424         24522.0  \n",
       "3           1.525907    7.520165       45.203016    5.224469         95091.0  \n",
       "4           0.606205    3.720433       33.638417    7.012956          8413.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_cleaned_df = jobs_df[['FIPS', 'State', 'County', 'PctEmpAgriculture', 'PctEmpMining', 'PctEmpConstruction', 'PctEmpManufacturing', 'PctEmpTrade', 'PctEmpTrans', 'PctEmpInformation', 'PctEmpFIRE', 'PctEmpServices', 'PctEmpGovt', 'NumCivEmployed']]\n",
    "jobs_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9227cccd-1195-44b7-a4c3-b7234aa4ccd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS                   0\n",
       "State                  0\n",
       "County                 0\n",
       "PctEmpAgriculture      0\n",
       "PctEmpMining           0\n",
       "PctEmpConstruction     0\n",
       "PctEmpManufacturing    0\n",
       "PctEmpTrade            0\n",
       "PctEmpTrans            0\n",
       "PctEmpInformation      0\n",
       "PctEmpFIRE             0\n",
       "PctEmpServices         0\n",
       "PctEmpGovt             0\n",
       "NumCivEmployed         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing null values with zeros\n",
    "jobs_cleaned_df = jobs_cleaned_df.fillna(0)\n",
    "jobs_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23935abc-e0dc-4bfa-b461-3f65489f0551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was saved to 'Resources/jobs_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file and Export\n",
    "jobs_cleaned = 'Resources/jobs_cleaned.csv'\n",
    "jobs_cleaned_df.to_csv(jobs_cleaned, index=False)\n",
    "print(f\"Data was saved to '{jobs_cleaned}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1469241-c3ce-40f2-a294-0d39120639f4",
   "metadata": {},
   "source": [
    "# UNEMPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4933056-8fd2-4d3e-ab00-4e586cc38050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Making the 'unemployment' DataFrame and CSV; thanks chatGPT\n",
    "# df = pd.DataFrame(jobs_df)\n",
    "\n",
    "# # Melt the DataFrame to get the desired format\n",
    "# df_melted = df.melt(id_vars=['FIPS', 'State', 'County'],\n",
    "#                    value_vars=['UnempRate2020', 'UnempRate2019', 'UnempRate2018', 'UnempRate2017', 'UnempRate2016', 'UnempRate2015', 'UnempRate2014', 'UnempRate2013', 'UnempRate2012', 'UnempRate2011', 'UnempRate2010', 'UnempRate2009', 'UnempRate2008', 'UnempRate2007'],\n",
    "#                    var_name='Year', value_name='UnempRate')\n",
    "# # Map the 'YEAR' column to the actual years\n",
    "# df_melted['Year'] = df_melted['Year'].str.replace('UnempRate', '')\n",
    "# df_melted['Year'] = df_melted['Year'].astype(int)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# unemployment_cleaned_df = df_melted\n",
    "# unemployment_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69e0b446-1723-43fd-b2f4-3f8f7d8a35d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Year</th>\n",
       "      <th>UnempRate</th>\n",
       "      <th>NumUnemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2020</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12933704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.9</td>\n",
       "      <td>131056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>2020</td>\n",
       "      <td>7.0</td>\n",
       "      <td>605.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45887</th>\n",
       "      <td>72145</td>\n",
       "      <td>PR</td>\n",
       "      <td>Vega Baja</td>\n",
       "      <td>2007</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45888</th>\n",
       "      <td>72147</td>\n",
       "      <td>PR</td>\n",
       "      <td>Vieques</td>\n",
       "      <td>2007</td>\n",
       "      <td>10.9</td>\n",
       "      <td>362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45889</th>\n",
       "      <td>72149</td>\n",
       "      <td>PR</td>\n",
       "      <td>Villalba</td>\n",
       "      <td>2007</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45890</th>\n",
       "      <td>72151</td>\n",
       "      <td>PR</td>\n",
       "      <td>Yabucoa</td>\n",
       "      <td>2007</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45891</th>\n",
       "      <td>72153</td>\n",
       "      <td>PR</td>\n",
       "      <td>Yauco</td>\n",
       "      <td>2007</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2184.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45892 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FIPS State         County  Year  UnempRate  NumUnemployed\n",
       "0          0    US  United States  2020        8.1     12933704.0\n",
       "1       1000    AL        Alabama  2020        5.9       131056.0\n",
       "2       1001    AL        Autauga  2020        4.9         1262.0\n",
       "3       1003    AL        Baldwin  2020        5.6         5425.0\n",
       "4       1005    AL        Barbour  2020        7.0          605.0\n",
       "...      ...   ...            ...   ...        ...            ...\n",
       "45887  72145    PR      Vega Baja  2007       12.6         2670.0\n",
       "45888  72147    PR        Vieques  2007       10.9          362.0\n",
       "45889  72149    PR       Villalba  2007       13.3         1256.0\n",
       "45890  72151    PR        Yabucoa  2007       18.2         2077.0\n",
       "45891  72153    PR          Yauco  2007       13.1         2184.0\n",
       "\n",
       "[45892 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Making the 'unemployment' DataFrame and CSV; thanks chatGPT\n",
    "# Assuming jobs_df is already defined as a DataFrame\n",
    "df = pd.DataFrame(jobs_df)\n",
    "\n",
    "# Melt the DataFrame for UnempRate\n",
    "df_unemp_rate = df.melt(\n",
    "    id_vars=['FIPS', 'State', 'County'],\n",
    "    value_vars=['UnempRate2020', 'UnempRate2019', 'UnempRate2018', 'UnempRate2017', 'UnempRate2016', 'UnempRate2015', 'UnempRate2014', 'UnempRate2013', 'UnempRate2012', 'UnempRate2011', 'UnempRate2010', 'UnempRate2009', 'UnempRate2008', 'UnempRate2007'],\n",
    "    var_name='Year', value_name='UnempRate'\n",
    ")\n",
    "\n",
    "# Extract the year from the 'Year' column for UnempRate\n",
    "df_unemp_rate['Year'] = df_unemp_rate['Year'].str.replace('UnempRate', '')\n",
    "df_unemp_rate['Year'] = df_unemp_rate['Year'].astype(int)\n",
    "\n",
    "# Melt the DataFrame for NumUnemployed\n",
    "df_num_unemployed = df.melt(\n",
    "    id_vars=['FIPS', 'State', 'County'],\n",
    "    value_vars=['NumUnemployed2020', 'NumUnemployed2019', 'NumUnemployed2018', 'NumUnemployed2017', 'NumUnemployed2016', 'NumUnemployed2015', 'NumUnemployed2014', 'NumUnemployed2013', 'NumUnemployed2012', 'NumUnemployed2011', 'NumUnemployed2010', 'NumUnemployed2009', 'NumUnemployed2008', 'NumUnemployed2007'],\n",
    "    var_name='Year', value_name='NumUnemployed'\n",
    ")\n",
    "\n",
    "# Extract the year from the 'Year' column for NumUnemployed\n",
    "df_num_unemployed['Year'] = df_num_unemployed['Year'].str.replace('NumUnemployed', '')\n",
    "df_num_unemployed['Year'] = df_num_unemployed['Year'].astype(int)\n",
    "\n",
    "# Merge the two melted DataFrames on the common columns\n",
    "unemployment_cleaned_df = pd.merge(df_unemp_rate, df_num_unemployed, on=['FIPS', 'State', 'County', 'Year'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "unemployment_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7d2dd83-2ec3-4e01-9348-bba6fd8bb949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS             0\n",
       "State            0\n",
       "County           0\n",
       "Year             0\n",
       "UnempRate        0\n",
       "NumUnemployed    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing null values with zeros\n",
    "unemployment_cleaned_df = unemployment_cleaned_df.fillna(0)\n",
    "unemployment_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "609bbb44-943b-4e6a-868c-4ce526de9dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS             0\n",
       "State            0\n",
       "County           0\n",
       "Year             0\n",
       "UnempRate        0\n",
       "NumUnemployed    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemployment_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b96e9546-2541-412e-925d-a1e4a20f15b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was saved to 'Resources/unemployment_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file and Export\n",
    "unemployment_cleaned = 'Resources/unemployment_cleaned.csv'\n",
    "unemployment_cleaned_df.to_csv(unemployment_cleaned, index=False)\n",
    "print(f\"Data was saved to '{unemployment_cleaned}\")\n",
    "\n",
    "# Y'all, I can't find this file :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f179d66-0209-4693-b4d5-cfe4657c2a3a",
   "metadata": {},
   "source": [
    "# EMPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0f09ccb-7c43-4162-ab30-8a75d2c89beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the 'employment' DataFrame and CSV; thanks chatGPT\n",
    "\n",
    "# Rename columns to be consistent\n",
    "jobs_df.rename(columns={\n",
    "    'NumCivLaborforce2020': 'NumCivLaborForce2020',\n",
    "    'NumCivLaborforce2019': 'NumCivLaborForce2019',\n",
    "    'NumCivLaborforce2018': 'NumCivLaborForce2018',\n",
    "    'NumCivLaborforce2017': 'NumCivLaborForce2017',\n",
    "    'NumCivLaborforce2016': 'NumCivLaborForce2016',\n",
    "    'NumCivLaborforce2015': 'NumCivLaborForce2015',\n",
    "    'NumCivLaborforce2014': 'NumCivLaborForce2014',\n",
    "    'NumCivLaborforce2013': 'NumCivLaborForce2013',\n",
    "    'NumCivLaborforce2007': 'NumCivLaborForce2007'\n",
    "}, inplace=True)\n",
    "\n",
    "df2 = pd.DataFrame(jobs_df)\n",
    "\n",
    "# # Melt the DataFrame to get the desired format\n",
    "# df2_melted = df2.melt(id_vars=['FIPS', 'State', 'County'],\n",
    "#                       value_vars=['NumCivLaborForce2012', 'NumCivLaborForce2011', 'NumCivLaborForce2010', 'NumCivLaborForce2009', 'NumCivLaborForce2008', 'NumCivLaborForce2020', 'NumCivLaborForce2019', 'NumCivLaborForce2018', 'NumCivLaborForce2016', 'NumCivLaborForce2015', 'NumCivLaborForce2014', 'NumCivLaborForce2013', 'NumCivLaborForce2007', 'NumCivLaborForce2017'],\n",
    "#                       var_name='Year', value_name='NumCivLaborForce')\n",
    "\n",
    "# # Map the 'Year' column to the actual years\n",
    "# df2_melted['Year'] = df2_melted['Year'].str.replace('NumCivLaborForce', '')\n",
    "# df2_melted['Year'] = df2_melted['Year'].astype(int)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# employment_cleaned_df = df2_melted\n",
    "# employment_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dbe6ac6-15f6-45fd-a94d-898037102694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Year</th>\n",
       "      <th>NumCivLaborForce</th>\n",
       "      <th>NumEmployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2012</td>\n",
       "      <td>155038121.0</td>\n",
       "      <td>142527201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2012</td>\n",
       "      <td>2178508.0</td>\n",
       "      <td>2000848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>2012</td>\n",
       "      <td>25762.0</td>\n",
       "      <td>23932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2012</td>\n",
       "      <td>84507.0</td>\n",
       "      <td>77973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>2012</td>\n",
       "      <td>9377.0</td>\n",
       "      <td>8273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45887</th>\n",
       "      <td>72145</td>\n",
       "      <td>PR</td>\n",
       "      <td>Vega Baja</td>\n",
       "      <td>2017</td>\n",
       "      <td>13414.0</td>\n",
       "      <td>11746.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45888</th>\n",
       "      <td>72147</td>\n",
       "      <td>PR</td>\n",
       "      <td>Vieques</td>\n",
       "      <td>2017</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>2589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45889</th>\n",
       "      <td>72149</td>\n",
       "      <td>PR</td>\n",
       "      <td>Villalba</td>\n",
       "      <td>2017</td>\n",
       "      <td>7557.0</td>\n",
       "      <td>6090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45890</th>\n",
       "      <td>72151</td>\n",
       "      <td>PR</td>\n",
       "      <td>Yabucoa</td>\n",
       "      <td>2017</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>7512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45891</th>\n",
       "      <td>72153</td>\n",
       "      <td>PR</td>\n",
       "      <td>Yauco</td>\n",
       "      <td>2017</td>\n",
       "      <td>10160.0</td>\n",
       "      <td>8409.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45892 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FIPS State         County  Year  NumCivLaborForce  NumEmployed\n",
       "0          0    US  United States  2012       155038121.0  142527201.0\n",
       "1       1000    AL        Alabama  2012         2178508.0    2000848.0\n",
       "2       1001    AL        Autauga  2012           25762.0      23932.0\n",
       "3       1003    AL        Baldwin  2012           84507.0      77973.0\n",
       "4       1005    AL        Barbour  2012            9377.0       8273.0\n",
       "...      ...   ...            ...   ...               ...          ...\n",
       "45887  72145    PR      Vega Baja  2017           13414.0      11746.0\n",
       "45888  72147    PR        Vieques  2017            3027.0       2589.0\n",
       "45889  72149    PR       Villalba  2017            7557.0       6090.0\n",
       "45890  72151    PR        Yabucoa  2017            9000.0       7512.0\n",
       "45891  72153    PR          Yauco  2017           10160.0       8409.0\n",
       "\n",
       "[45892 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming jobs_df is already defined as a DataFrame\n",
    "df2 = pd.DataFrame(jobs_df)\n",
    "\n",
    "# Melt the DataFrame for NumCivLaborForce\n",
    "df2_melted_laborforce = df2.melt(\n",
    "    id_vars=['FIPS', 'State', 'County'],\n",
    "    value_vars=['NumCivLaborForce2012', 'NumCivLaborForce2011', 'NumCivLaborForce2010', 'NumCivLaborForce2009', 'NumCivLaborForce2008', 'NumCivLaborForce2020', 'NumCivLaborForce2019', 'NumCivLaborForce2018', 'NumCivLaborForce2016', 'NumCivLaborForce2015', 'NumCivLaborForce2014', 'NumCivLaborForce2013', 'NumCivLaborForce2007', 'NumCivLaborForce2017'],\n",
    "    var_name='Year', value_name='NumCivLaborForce'\n",
    ")\n",
    "\n",
    "# Extract the year from the 'Year' column for NumCivLaborForce\n",
    "df2_melted_laborforce['Year'] = df2_melted_laborforce['Year'].str.replace('NumCivLaborForce', '')\n",
    "df2_melted_laborforce['Year'] = df2_melted_laborforce['Year'].astype(int)\n",
    "\n",
    "# Melt the DataFrame for NumEmployed\n",
    "df2_melted_employed = df2.melt(\n",
    "    id_vars=['FIPS', 'State', 'County'],\n",
    "    value_vars=['NumEmployed2011', 'NumEmployed2010', 'NumEmployed2009', 'NumEmployed2008', 'NumEmployed2020', 'NumEmployed2019', 'NumEmployed2018', 'NumEmployed2017', 'NumEmployed2016', 'NumEmployed2012', 'NumEmployed2015', 'NumEmployed2014', 'NumEmployed2013', 'NumEmployed2007'],\n",
    "    var_name='Year', value_name='NumEmployed'\n",
    ")\n",
    "\n",
    "# Extract the year from the 'Year' column for NumEmployed\n",
    "df2_melted_employed['Year'] = df2_melted_employed['Year'].str.replace('NumEmployed', '')\n",
    "df2_melted_employed['Year'] = df2_melted_employed['Year'].astype(int)\n",
    "\n",
    "# Merge the two melted DataFrames on the common columns\n",
    "employment_cleaned_df = pd.merge(df2_melted_laborforce, df2_melted_employed, on=['FIPS', 'State', 'County', 'Year'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "employment_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d84bb9b5-743a-42a5-ad1c-30841a7a7105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS                0\n",
       "State               0\n",
       "County              0\n",
       "Year                0\n",
       "NumCivLaborForce    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing null values with zeros\n",
    "employment_cleaned_df = employment_cleaned_df.fillna(0)\n",
    "employment_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83fc5d8e-7613-44a8-a0d2-ccfba4824316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was saved to 'Resources/employment_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file and Export\n",
    "employment_cleaned = 'Resources/employment_cleaned.csv'\n",
    "employment_cleaned_df.to_csv(employment_cleaned, index=False)\n",
    "print(f\"Data was saved to '{employment_cleaned}\")\n",
    "\n",
    "# Y'all, I can't find this file :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106dbf2-cfc7-4ff6-b55c-6741e88b1bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54fca19-2297-4cf9-aecb-e7d9a5358e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r'C:\\Users\\laura\\OneDrive\\Desktop\\Boothcamps\\April_ds_boothcamp\\projects\\project_3_group_12\\Project-3---Web-Application-Data-Analytics\\archive (1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02833867-4a1e-4cbb-a222-5ff3befc5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "county_classifications_path = os.path.join(base_path, 'County Classifications.csv')\n",
    "income_path = os.path.join(base_path, 'Income.csv')\n",
    "jobs_path = os.path.join(base_path, 'Jobs.csv')\n",
    "people_path = os.path.join(base_path, 'People.csv')\n",
    "rural_atlas_data_path = os.path.join(base_path, 'RuralAtlasData23.xlsx')\n",
    "variable_name_lookup_path = os.path.join(base_path, 'Variable Name Lookup.csv')\n",
    "veterans_path = os.path.join(base_path, 'Veterans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc98ed2-360d-4660-a5d2-808af3139236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "county_classifications = pd.read_csv(county_classifications_path, encoding='ISO-8859-1')\n",
    "income = pd.read_csv(income_path)\n",
    "jobs = pd.read_csv(jobs_path)\n",
    "people = pd.read_csv(people_path)\n",
    "rural_atlas_data = pd.read_excel(rural_atlas_data_path)\n",
    "variable_name_lookup = pd.read_csv(variable_name_lookup_path)\n",
    "veterans = pd.read_csv(veterans_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a0afd-b3c9-46c5-972c-8e6065d234cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store datasets for easy looping\n",
    "datasets = {\n",
    "    \"County Classifications\": county_classifications,\n",
    "    \"Income\": income,\n",
    "    \"Jobs\": jobs,\n",
    "    \"People\": people,\n",
    "    \"Rural Atlas Data\": rural_atlas_data,\n",
    "    \"Variable Name Lookup\": variable_name_lookup,\n",
    "    \"Veterans\": veterans\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e780f334-0416-48a3-b488-5585d06a0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Inspection\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc373c1-14b2-4293-be85-a291832f42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Summary statistics for {name}:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf25cd6-4e49-4ae1-925e-02658a23c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "for name, df in datasets.items():\n",
    "    # Select only numeric columns for correlation analysis\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "    \n",
    "    if numeric_df.shape[1] > 1:  # Only plot if there are multiple numeric columns\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')\n",
    "        plt.title(f\"Correlation Matrix for {name}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b4da4-789f-4e02-848c-936fc6cff28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Distributions\n",
    "for name, df in datasets.items():\n",
    "    numeric_df = df.select_dtypes(include=['number'])  # Select only numeric columns\n",
    "    if not numeric_df.empty:  # Check if there are any numeric columns to plot\n",
    "        numeric_df.hist(figsize=(15, 10), bins=30)\n",
    "        plt.suptitle(f\"Histograms for {name}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No numeric columns to plot histograms for {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7bf262-24db-4995-89c5-cf8e54bdc3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Categorical Variables\n",
    "for name, df in datasets.items():\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        print(f\"Value counts for {col} in {name}:\")\n",
    "        print(df[col].value_counts())\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88508c-c705-4580-9536-b673ecabb103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to load the file with different delimiters\n",
    "try:\n",
    "    # Attempt to load with tab delimiter\n",
    "    county_classifications = pd.read_csv(county_classifications_path, delimiter='\\t', encoding='ISO-8859-1')\n",
    "except:\n",
    "    print(\"Tab delimiter didn't work. Trying comma delimiter.\")\n",
    "    try:\n",
    "        # Attempt to load with comma delimiter\n",
    "        county_classifications = pd.read_csv(county_classifications_path, delimiter=',', encoding='ISO-8859-1')\n",
    "    except Exception as e:\n",
    "        print(\"Comma delimiter also failed. Please inspect the file format.\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Display the first few rows to inspect if data loaded correctly\n",
    "print(county_classifications.head())\n",
    "print(county_classifications.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eed430-aa01-4dc0-96f0-19974627a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Cleaned Data (Optional)\n",
    "for name, df in datasets.items():\n",
    "    df.to_csv(f'cleaned_{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbe5bd-610c-45ad-bb2f-c135bf01d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the cleaned data for verification (First 5 rows of each)\n",
    "cleaned_files = {name: df.head() for name, df in datasets.items()}\n",
    "cleaned_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6036c-eaa1-4bfc-924f-b418184831a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7ff14-e90c-4988-99a0-febb7c07a2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
