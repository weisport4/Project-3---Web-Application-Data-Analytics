{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c247d9-00cf-43f1-a393-179aa02a7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c18224-2a82-4238-937d-d8f93e3af32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>UnempRate2020</th>\n",
       "      <th>PctEmpChange1920</th>\n",
       "      <th>UnempRate2019</th>\n",
       "      <th>PctEmpChange1819</th>\n",
       "      <th>UnempRate2018</th>\n",
       "      <th>UnempRate2017</th>\n",
       "      <th>UnempRate2016</th>\n",
       "      <th>...</th>\n",
       "      <th>NumUnemployed2015</th>\n",
       "      <th>NumUnemployed2014</th>\n",
       "      <th>NumEmployed2014</th>\n",
       "      <th>NumCivLaborforce2014</th>\n",
       "      <th>NumUnemployed2013</th>\n",
       "      <th>NumCivLaborforce2013</th>\n",
       "      <th>NumUnemployed2007</th>\n",
       "      <th>NumEmployed2007</th>\n",
       "      <th>NumCivLaborforce2007</th>\n",
       "      <th>NumCivLaborforce2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>8.1</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>8285731.0</td>\n",
       "      <td>9617207.0</td>\n",
       "      <td>146318952.0</td>\n",
       "      <td>155936159.0</td>\n",
       "      <td>11457241.0</td>\n",
       "      <td>155362278.0</td>\n",
       "      <td>7034917.0</td>\n",
       "      <td>145156133.0</td>\n",
       "      <td>152191050.0</td>\n",
       "      <td>160214378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5.9</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>...</td>\n",
       "      <td>131852.0</td>\n",
       "      <td>146010.0</td>\n",
       "      <td>2018705.0</td>\n",
       "      <td>2164715.0</td>\n",
       "      <td>159274.0</td>\n",
       "      <td>2172102.0</td>\n",
       "      <td>88418.0</td>\n",
       "      <td>2092030.0</td>\n",
       "      <td>2180448.0</td>\n",
       "      <td>2172455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>24150.0</td>\n",
       "      <td>25639.0</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>25783.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>23610.0</td>\n",
       "      <td>24434.0</td>\n",
       "      <td>25898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>4874.0</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>81265.0</td>\n",
       "      <td>86546.0</td>\n",
       "      <td>5740.0</td>\n",
       "      <td>85206.0</td>\n",
       "      <td>2616.0</td>\n",
       "      <td>80213.0</td>\n",
       "      <td>82829.0</td>\n",
       "      <td>91838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>...</td>\n",
       "      <td>767.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>7930.0</td>\n",
       "      <td>8859.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>9096.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>9698.0</td>\n",
       "      <td>10363.0</td>\n",
       "      <td>8298.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS State         County  UnempRate2020  PctEmpChange1920  UnempRate2019  \\\n",
       "0     0    US  United States            8.1              -6.0            3.7   \n",
       "1  1000    AL        Alabama            5.9              -3.2            3.0   \n",
       "2  1001    AL        Autauga            4.9              -3.9            2.7   \n",
       "3  1003    AL        Baldwin            5.6              -3.6            2.8   \n",
       "4  1005    AL        Barbour            7.0              -2.4            3.8   \n",
       "\n",
       "   PctEmpChange1819  UnempRate2018  UnempRate2017  UnempRate2016  ...  \\\n",
       "0               1.3            3.9            4.4            4.9  ...   \n",
       "1               2.3            3.9            4.6            5.9  ...   \n",
       "2               1.7            3.6            4.0            5.1  ...   \n",
       "3               3.7            3.6            4.2            5.4  ...   \n",
       "4               2.9            5.1            6.0            8.4  ...   \n",
       "\n",
       "   NumUnemployed2015  NumUnemployed2014  NumEmployed2014  \\\n",
       "0          8285731.0          9617207.0      146318952.0   \n",
       "1           131852.0           146010.0        2018705.0   \n",
       "2             1335.0             1489.0          24150.0   \n",
       "3             4874.0             5281.0          81265.0   \n",
       "4              767.0              929.0           7930.0   \n",
       "\n",
       "   NumCivLaborforce2014  NumUnemployed2013  NumCivLaborforce2013  \\\n",
       "0           155936159.0         11457241.0           155362278.0   \n",
       "1             2164715.0           159274.0             2172102.0   \n",
       "2               25639.0             1628.0               25783.0   \n",
       "3               86546.0             5740.0               85206.0   \n",
       "4                8859.0              944.0                9096.0   \n",
       "\n",
       "   NumUnemployed2007  NumEmployed2007  NumCivLaborforce2007  \\\n",
       "0          7034917.0      145156133.0           152191050.0   \n",
       "1            88418.0        2092030.0             2180448.0   \n",
       "2              824.0          23610.0               24434.0   \n",
       "3             2616.0          80213.0               82829.0   \n",
       "4              665.0           9698.0               10363.0   \n",
       "\n",
       "   NumCivLaborforce2017  \n",
       "0           160214378.0  \n",
       "1             2172455.0  \n",
       "2               25898.0  \n",
       "3               91838.0  \n",
       "4                8298.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a Pandas DataFrame\n",
    "jobs_df = pd.read_csv('Resources/jobs.csv')\n",
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133be9ad-ec88-48f7-b940-008477806762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3278 entries, 0 to 3277\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   FIPS                   3278 non-null   int64  \n",
      " 1   State                  3278 non-null   object \n",
      " 2   County                 3278 non-null   object \n",
      " 3   Median_HH_Inc_ACS      3273 non-null   float64\n",
      " 4   PerCapitaInc           3273 non-null   float64\n",
      " 5   Poverty_Rate_0_17_ACS  3272 non-null   float64\n",
      " 6   Poverty_Rate_ACS       3273 non-null   float64\n",
      " 7   Deep_Pov_All           3273 non-null   float64\n",
      " 8   Deep_Pov_Children      3273 non-null   float64\n",
      " 9   NumAll_inPOV_ACS       3273 non-null   float64\n",
      " 10  PCTPOV017              3193 non-null   float64\n",
      " 11  POV017                 3193 non-null   float64\n",
      " 12  MedHHInc               3193 non-null   float64\n",
      " 13  POVALL                 3193 non-null   float64\n",
      " 14  PCTPOVALL              3193 non-null   float64\n",
      " 15  Num_inPOV_0_17_ACS     3273 non-null   float64\n",
      "dtypes: float64(13), int64(1), object(2)\n",
      "memory usage: 409.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read the data into a Pandas DataFrame\n",
    "income_df = pd.read_csv('Resources/income.csv')\n",
    "income_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43850744-4e8e-49ea-a0d2-7dd6179002dc",
   "metadata": {},
   "source": [
    "# JOBS AND INCOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed506b-0375-4e38-9725-fe495f0909e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a brief summary of the crowdfunding_info DataFrame.\n",
    "jobs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1ccf7-c8dd-49c7-9a03-6dab4d5570fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values:\n",
    "jobs_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93dec6-9b8c-4b12-8aa6-badaa84aa916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values with zeros\n",
    "jobs_df = jobs_df.fillna(0)\n",
    "jobs_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b1f1e-2fbf-434e-bbf6-cb73eb710f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nulls in 'income.csv'?\n",
    "income_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16020fc7-0c39-4e95-9667-dd4b5673e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values with zeros\n",
    "income_cleaned_df = income_df.fillna(0)\n",
    "income_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0718703d-4432-4e55-8c6e-d369c06c5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file and Export\n",
    "income_cleaned = 'Resources/income_cleaned.csv'\n",
    "income_cleaned_df.to_csv(income_cleaned, index=False)\n",
    "print(f\"Data was saved to '{income_cleaned}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6e0584-a68e-4cf4-bb44-41a3b82ef2a4",
   "metadata": {},
   "source": [
    "# JOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc5ee9-c73b-4646-9336-9d462a86cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_cleaned_df = jobs_df[['FIPS', 'State', 'County', 'PctEmpAgriculture', 'PctEmpMining', 'PctEmpConstruction', 'PctEmpManufacturing', 'PctEmpTrade', 'PctEmpTrans', 'PctEmpInformation', 'PctEmpFIRE', 'PctEmpServices', 'PctEmpGovt', 'NumCivEmployed']]\n",
    "jobs_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227cccd-1195-44b7-a4c3-b7234aa4ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values with zeros\n",
    "jobs_cleaned_df = jobs_cleaned_df.fillna(0)\n",
    "jobs_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23935abc-e0dc-4bfa-b461-3f65489f0551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file and Export\n",
    "jobs_cleaned = 'Resources/jobs_cleaned.csv'\n",
    "jobs_cleaned_df.to_csv(jobs_cleaned, index=False)\n",
    "print(f\"Data was saved to '{jobs_cleaned}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1469241-c3ce-40f2-a294-0d39120639f4",
   "metadata": {},
   "source": [
    "# UNEMPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4933056-8fd2-4d3e-ab00-4e586cc38050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Making the 'unemployment' DataFrame and CSV; thanks chatGPT\n",
    "# df = pd.DataFrame(jobs_df)\n",
    "\n",
    "# # Melt the DataFrame to get the desired format\n",
    "# df_melted = df.melt(id_vars=['FIPS', 'State', 'County'],\n",
    "#                    value_vars=['UnempRate2020', 'UnempRate2019', 'UnempRate2018', 'UnempRate2017', 'UnempRate2016', 'UnempRate2015', 'UnempRate2014', 'UnempRate2013', 'UnempRate2012', 'UnempRate2011', 'UnempRate2010', 'UnempRate2009', 'UnempRate2008', 'UnempRate2007'],\n",
    "#                    var_name='Year', value_name='UnempRate')\n",
    "# # Map the 'YEAR' column to the actual years\n",
    "# df_melted['Year'] = df_melted['Year'].str.replace('UnempRate', '')\n",
    "# df_melted['Year'] = df_melted['Year'].astype(int)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# unemployment_cleaned_df = df_melted\n",
    "# unemployment_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e0b446-1723-43fd-b2f4-3f8f7d8a35d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Year</th>\n",
       "      <th>UnempRate</th>\n",
       "      <th>NumUnemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12933704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.9</td>\n",
       "      <td>131056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>2020</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>2020</td>\n",
       "      <td>7.0</td>\n",
       "      <td>605.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45887</th>\n",
       "      <td>72145</td>\n",
       "      <td>2007</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45888</th>\n",
       "      <td>72147</td>\n",
       "      <td>2007</td>\n",
       "      <td>10.9</td>\n",
       "      <td>362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45889</th>\n",
       "      <td>72149</td>\n",
       "      <td>2007</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45890</th>\n",
       "      <td>72151</td>\n",
       "      <td>2007</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45891</th>\n",
       "      <td>72153</td>\n",
       "      <td>2007</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2184.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45892 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FIPS  Year  UnempRate  NumUnemployed\n",
       "0          0  2020        8.1     12933704.0\n",
       "1       1000  2020        5.9       131056.0\n",
       "2       1001  2020        4.9         1262.0\n",
       "3       1003  2020        5.6         5425.0\n",
       "4       1005  2020        7.0          605.0\n",
       "...      ...   ...        ...            ...\n",
       "45887  72145  2007       12.6         2670.0\n",
       "45888  72147  2007       10.9          362.0\n",
       "45889  72149  2007       13.3         1256.0\n",
       "45890  72151  2007       18.2         2077.0\n",
       "45891  72153  2007       13.1         2184.0\n",
       "\n",
       "[45892 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Making the 'unemployment' DataFrame and CSV; thanks chatGPT\n",
    "# Assuming jobs_df is already defined as a DataFrame\n",
    "df = pd.DataFrame(jobs_df)\n",
    "\n",
    "# Melt the DataFrame for UnempRate\n",
    "df_unemp_rate = df.melt(\n",
    "    id_vars=['FIPS'],\n",
    "    value_vars=['UnempRate2020', 'UnempRate2019', 'UnempRate2018', 'UnempRate2017', 'UnempRate2016', 'UnempRate2015', 'UnempRate2014', 'UnempRate2013', 'UnempRate2012', 'UnempRate2011', 'UnempRate2010', 'UnempRate2009', 'UnempRate2008', 'UnempRate2007'],\n",
    "    var_name='Year', value_name='UnempRate'\n",
    ")\n",
    "\n",
    "# Extract the year from the 'Year' column for UnempRate\n",
    "df_unemp_rate['Year'] = df_unemp_rate['Year'].str.replace('UnempRate', '')\n",
    "df_unemp_rate['Year'] = df_unemp_rate['Year'].astype(int)\n",
    "\n",
    "# Melt the DataFrame for NumUnemployed\n",
    "df_num_unemployed = df.melt(\n",
    "    id_vars=['FIPS'],\n",
    "    value_vars=['NumUnemployed2020', 'NumUnemployed2019', 'NumUnemployed2018', 'NumUnemployed2017', 'NumUnemployed2016', 'NumUnemployed2015', 'NumUnemployed2014', 'NumUnemployed2013', 'NumUnemployed2012', 'NumUnemployed2011', 'NumUnemployed2010', 'NumUnemployed2009', 'NumUnemployed2008', 'NumUnemployed2007'],\n",
    "    var_name='Year', value_name='NumUnemployed'\n",
    ")\n",
    "\n",
    "# Extract the year from the 'Year' column for NumUnemployed\n",
    "df_num_unemployed['Year'] = df_num_unemployed['Year'].str.replace('NumUnemployed', '')\n",
    "df_num_unemployed['Year'] = df_num_unemployed['Year'].astype(int)\n",
    "\n",
    "# Merge the two melted DataFrames on the common columns\n",
    "unemployment_cleaned_df = pd.merge(df_unemp_rate, df_num_unemployed, on=['FIPS', 'Year'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "unemployment_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d2dd83-2ec3-4e01-9348-bba6fd8bb949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS             0\n",
       "Year             0\n",
       "UnempRate        0\n",
       "NumUnemployed    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing null values with zeros\n",
    "unemployment_cleaned_df = unemployment_cleaned_df.fillna(0)\n",
    "unemployment_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "609bbb44-943b-4e6a-868c-4ce526de9dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS             0\n",
       "Year             0\n",
       "UnempRate        0\n",
       "NumUnemployed    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemployment_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a93d7d7-c5df-47f0-8687-399f5a08f604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIPS 0 appears in the following rows:\n",
      "   FIPS State         County  UnempRate2020  PctEmpChange1920  UnempRate2019  \\\n",
      "0     0    US  United States            8.1              -6.0            3.7   \n",
      "\n",
      "   PctEmpChange1819  UnempRate2018  UnempRate2017  UnempRate2016  ...  \\\n",
      "0               1.3            3.9            4.4            4.9  ...   \n",
      "\n",
      "   NumUnemployed2015  NumUnemployed2014  NumEmployed2014  \\\n",
      "0          8285731.0          9617207.0      146318952.0   \n",
      "\n",
      "   NumCivLaborforce2014  NumUnemployed2013  NumCivLaborforce2013  \\\n",
      "0           155936159.0         11457241.0           155362278.0   \n",
      "\n",
      "   NumUnemployed2007  NumEmployed2007  NumCivLaborforce2007  \\\n",
      "0          7034917.0      145156133.0           152191050.0   \n",
      "\n",
      "   NumCivLaborforce2017  \n",
      "0           160214378.0  \n",
      "\n",
      "[1 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find all duplicated FIPS values\n",
    "duplicates = unemployment_cleaned_df[unemployment_cleaned_df.duplicated(subset='FIPS', keep=False)]\n",
    "\n",
    "if not duplicates.empty:\n",
    "    # Get unique duplicated FIPS values\n",
    "    duplicate_fips = duplicates['FIPS'].unique()\n",
    "\n",
    "    # Choose the first duplicated FIPS value (or select another as needed)\n",
    "    fips_to_check = duplicate_fips[0]\n",
    "\n",
    "    # Find rows with this duplicated FIPS value\n",
    "    matching_rows = df[df['FIPS'] == fips_to_check]\n",
    "\n",
    "    # Print the chosen duplicate and its matching rows\n",
    "    print(f\"FIPS {fips_to_check} appears in the following rows:\")\n",
    "    print(matching_rows)\n",
    "else:\n",
    "    print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001e5db-4fb1-4481-bba8-6d9bbfb8e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_rows = df[df['FIPS'] == fips_to_check]\n",
    "print(f\"FIPS {fips_to_check} appears in the following rows:\")\n",
    "print(matching_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e9546-2541-412e-925d-a1e4a20f15b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file and Export\n",
    "unemployment_cleaned = 'Resources/unemployment_cleaned.csv'\n",
    "unemployment_cleaned_df.to_csv(unemployment_cleaned, index=False)\n",
    "print(f\"Data was saved to '{unemployment_cleaned}\")\n",
    "\n",
    "# Y'all, I can't find this file :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f179d66-0209-4693-b4d5-cfe4657c2a3a",
   "metadata": {},
   "source": [
    "# EMPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f09ccb-7c43-4162-ab30-8a75d2c89beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the 'employment' DataFrame and CSV; thanks chatGPT\n",
    "\n",
    "# Rename columns to be consistent\n",
    "jobs_df.rename(columns={\n",
    "    'NumCivLaborforce2020': 'NumCivLaborForce2020',\n",
    "    'NumCivLaborforce2019': 'NumCivLaborForce2019',\n",
    "    'NumCivLaborforce2018': 'NumCivLaborForce2018',\n",
    "    'NumCivLaborforce2017': 'NumCivLaborForce2017',\n",
    "    'NumCivLaborforce2016': 'NumCivLaborForce2016',\n",
    "    'NumCivLaborforce2015': 'NumCivLaborForce2015',\n",
    "    'NumCivLaborforce2014': 'NumCivLaborForce2014',\n",
    "    'NumCivLaborforce2013': 'NumCivLaborForce2013',\n",
    "    'NumCivLaborforce2007': 'NumCivLaborForce2007'\n",
    "}, inplace=True)\n",
    "\n",
    "df2 = pd.DataFrame(jobs_df)\n",
    "\n",
    "# # Melt the DataFrame to get the desired format\n",
    "# df2_melted = df2.melt(id_vars=['FIPS'],\n",
    "#                       value_vars=['NumCivLaborForce2012', 'NumCivLaborForce2011', 'NumCivLaborForce2010', 'NumCivLaborForce2009', 'NumCivLaborForce2008', 'NumCivLaborForce2020', 'NumCivLaborForce2019', 'NumCivLaborForce2018', 'NumCivLaborForce2016', 'NumCivLaborForce2015', 'NumCivLaborForce2014', 'NumCivLaborForce2013', 'NumCivLaborForce2007', 'NumCivLaborForce2017'],\n",
    "#                       var_name='Year', value_name='NumCivLaborForce')\n",
    "\n",
    "# # Map the 'Year' column to the actual years\n",
    "# df2_melted['Year'] = df2_melted['Year'].str.replace('NumCivLaborForce', '')\n",
    "# df2_melted['Year'] = df2_melted['Year'].astype(int)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# employment_cleaned_df = df2_melted\n",
    "# employment_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe6ac6-15f6-45fd-a94d-898037102694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming jobs_df is already defined as a DataFrame\n",
    "df2 = pd.DataFrame(jobs_df)\n",
    "\n",
    "# Melt the DataFrame for NumCivLaborForce\n",
    "df2_melted_laborforce = df2.melt(\n",
    "    id_vars=['FIPS', 'State', 'County'],\n",
    "    value_vars=['NumCivLaborForce2012', 'NumCivLaborForce2011', 'NumCivLaborForce2010', 'NumCivLaborForce2009', 'NumCivLaborForce2008', 'NumCivLaborForce2020', 'NumCivLaborForce2019', 'NumCivLaborForce2018', 'NumCivLaborForce2016', 'NumCivLaborForce2015', 'NumCivLaborForce2014', 'NumCivLaborForce2013', 'NumCivLaborForce2007', 'NumCivLaborForce2017'],\n",
    "    var_name='Year', value_name='NumCivLaborForce'\n",
    ")\n",
    "\n",
    "# Extract the year from the 'Year' column for NumCivLaborForce\n",
    "df2_melted_laborforce['Year'] = df2_melted_laborforce['Year'].str.replace('NumCivLaborForce', '')\n",
    "df2_melted_laborforce['Year'] = df2_melted_laborforce['Year'].astype(int)\n",
    "\n",
    "# Melt the DataFrame for NumEmployed\n",
    "df2_melted_employed = df2.melt(\n",
    "    id_vars=['FIPS', 'State', 'County'],\n",
    "    value_vars=['NumEmployed2011', 'NumEmployed2010', 'NumEmployed2009', 'NumEmployed2008', 'NumEmployed2020', 'NumEmployed2019', 'NumEmployed2018', 'NumEmployed2017', 'NumEmployed2016', 'NumEmployed2012', 'NumEmployed2015', 'NumEmployed2014', 'NumEmployed2013', 'NumEmployed2007'],\n",
    "    var_name='Year', value_name='NumEmployed'\n",
    ")\n",
    "\n",
    "# Extract the year from the 'Year' column for NumEmployed\n",
    "df2_melted_employed['Year'] = df2_melted_employed['Year'].str.replace('NumEmployed', '')\n",
    "df2_melted_employed['Year'] = df2_melted_employed['Year'].astype(int)\n",
    "\n",
    "# Merge the two melted DataFrames on the common columns\n",
    "employment_cleaned_df = pd.merge(df2_melted_laborforce, df2_melted_employed, on=['FIPS', 'State', 'County', 'Year'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "employment_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bb9b5-743a-42a5-ad1c-30841a7a7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values with zeros\n",
    "employment_cleaned_df = employment_cleaned_df.fillna(0)\n",
    "employment_cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc5d8e-7613-44a8-a0d2-ccfba4824316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file and Export\n",
    "employment_cleaned = 'Resources/employment_cleaned.csv'\n",
    "employment_cleaned_df.to_csv(employment_cleaned, index=False)\n",
    "print(f\"Data was saved to '{employment_cleaned}\")\n",
    "\n",
    "# Y'all, I can't find this file :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54fca19-2297-4cf9-aecb-e7d9a5358e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r'C:\\Users\\laura\\OneDrive\\Desktop\\Boothcamps\\April_ds_boothcamp\\projects\\project_3_group_12\\Project-3---Web-Application-Data-Analytics\\archive (1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02833867-4a1e-4cbb-a222-5ff3befc5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "county_classifications_path = os.path.join(base_path, 'County Classifications.csv')\n",
    "income_path = os.path.join(base_path, 'Income.csv')\n",
    "jobs_path = os.path.join(base_path, 'Jobs.csv')\n",
    "people_path = os.path.join(base_path, 'People.csv')\n",
    "rural_atlas_data_path = os.path.join(base_path, 'RuralAtlasData23.xlsx')\n",
    "variable_name_lookup_path = os.path.join(base_path, 'Variable Name Lookup.csv')\n",
    "veterans_path = os.path.join(base_path, 'Veterans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc98ed2-360d-4660-a5d2-808af3139236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "county_classifications = pd.read_csv(county_classifications_path, encoding='ISO-8859-1')\n",
    "income = pd.read_csv(income_path)\n",
    "jobs = pd.read_csv(jobs_path)\n",
    "people = pd.read_csv(people_path)\n",
    "rural_atlas_data = pd.read_excel(rural_atlas_data_path)\n",
    "variable_name_lookup = pd.read_csv(variable_name_lookup_path)\n",
    "veterans = pd.read_csv(veterans_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a0afd-b3c9-46c5-972c-8e6065d234cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store datasets for easy looping\n",
    "datasets = {\n",
    "    \"County Classifications\": county_classifications,\n",
    "    \"Income\": income,\n",
    "    \"Jobs\": jobs,\n",
    "    \"People\": people,\n",
    "    \"Rural Atlas Data\": rural_atlas_data,\n",
    "    \"Variable Name Lookup\": variable_name_lookup,\n",
    "    \"Veterans\": veterans\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e780f334-0416-48a3-b488-5585d06a0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Inspection\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc373c1-14b2-4293-be85-a291832f42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Summary statistics for {name}:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf25cd6-4e49-4ae1-925e-02658a23c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "for name, df in datasets.items():\n",
    "    # Select only numeric columns for correlation analysis\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "    \n",
    "    if numeric_df.shape[1] > 1:  # Only plot if there are multiple numeric columns\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')\n",
    "        plt.title(f\"Correlation Matrix for {name}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b4da4-789f-4e02-848c-936fc6cff28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Distributions\n",
    "for name, df in datasets.items():\n",
    "    numeric_df = df.select_dtypes(include=['number'])  # Select only numeric columns\n",
    "    if not numeric_df.empty:  # Check if there are any numeric columns to plot\n",
    "        numeric_df.hist(figsize=(15, 10), bins=30)\n",
    "        plt.suptitle(f\"Histograms for {name}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No numeric columns to plot histograms for {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7bf262-24db-4995-89c5-cf8e54bdc3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Categorical Variables\n",
    "for name, df in datasets.items():\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        print(f\"Value counts for {col} in {name}:\")\n",
    "        print(df[col].value_counts())\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88508c-c705-4580-9536-b673ecabb103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to load the file with different delimiters\n",
    "try:\n",
    "    # Attempt to load with tab delimiter\n",
    "    county_classifications = pd.read_csv(county_classifications_path, delimiter='\\t', encoding='ISO-8859-1')\n",
    "except:\n",
    "    print(\"Tab delimiter didn't work. Trying comma delimiter.\")\n",
    "    try:\n",
    "        # Attempt to load with comma delimiter\n",
    "        county_classifications = pd.read_csv(county_classifications_path, delimiter=',', encoding='ISO-8859-1')\n",
    "    except Exception as e:\n",
    "        print(\"Comma delimiter also failed. Please inspect the file format.\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Display the first few rows to inspect if data loaded correctly\n",
    "print(county_classifications.head())\n",
    "print(county_classifications.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eed430-aa01-4dc0-96f0-19974627a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Cleaned Data (Optional)\n",
    "for name, df in datasets.items():\n",
    "    df.to_csv(f'cleaned_{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbe5bd-610c-45ad-bb2f-c135bf01d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the cleaned data for verification (First 5 rows of each)\n",
    "cleaned_files = {name: df.head() for name, df in datasets.items()}\n",
    "cleaned_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6036c-eaa1-4bfc-924f-b418184831a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7ff14-e90c-4988-99a0-febb7c07a2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
